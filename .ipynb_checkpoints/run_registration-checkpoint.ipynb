{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788892dc",
   "metadata": {},
   "source": [
    "# what does this notebook do:\n",
    "1. load the data, \n",
    "2. process the data for the following steps.\n",
    "3. registration\n",
    "    step 1. run point set matching (ICP)  \n",
    "    step 2. tune the consensus set parameters.  \n",
    "    step 3. run maximum-rotation-set  \n",
    "    step 4. neighborhood matching  \n",
    "    step 5. find the non-rigid transformation  \n",
    "4. count the matching cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time,sys,glob,os\n",
    "import pandas as pd\n",
    "import scipy.ndimage as ndi\n",
    "import cc3d\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "from skimage import color, morphology, measure\n",
    "from skimage.transform import downscale_local_mean\n",
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from cellregister import *\n",
    "from iterive_non_rigid import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68934f",
   "metadata": {},
   "source": [
    "# 1. load the data\n",
    "- we will need four data as pickle files, including the two original images (`img1.pkl` and `img2.pkl`) and two segmented images (`img1_seg.pkl` and `img2_seg.pkl`).\n",
    "- note that the two images do not need to be on the same size but the corresponding segmented images have to be. \n",
    "- we use `z` and `nd2` to refer these two *in vivo* and *ex vivo* images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb149a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/' # put your data here. \n",
    "z_f = pickle.load(open(data_dir + '/img1.pkl', 'rb'))\n",
    "nd2_f = pickle.load(open(data_dir + '/img2.pkl', 'rb'))\n",
    "seg_cc_f_zstack = pickle.load(open(data_dir + '/img1_seg.pkl', 'rb'))\n",
    "seg_cc_f_nd2 = pickle.load(open(data_dir + '/img1_seg.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b166f5b",
   "metadata": {},
   "source": [
    "# 2. Setup\n",
    "set up the parameters here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_edge = np.array((10,100,100))\n",
    "outputshape = add_edge*2\n",
    "\n",
    "max_iteration = 100  # shape ICP max iteration \n",
    "thre = 3 # shape ICP parametrs\n",
    "ds_sz = 5 # shape ICP downsample size\n",
    "with_scaling = True # shape ICP learn the scaling \n",
    "ds_sz_aff=3 # NCC downsample size\n",
    "vec_ds = 3 # vector field downsample size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635af42",
   "metadata": {},
   "source": [
    "# 3. Process two images\n",
    "- this will generate the variables needed in the following steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zstack_mask,zstack_dims,zstack_cells,zstack_bb,num_cells_list_zstack,pcd_j_ds_list,im2p_list=generate_stuff(z_f,seg_cc_f_zstack, add_edge, ds_sz, outputshape, ds_sz_aff)\n",
    "nd2_mask,nd2_dims,nd2_cells,nd2_bb,num_cells_list_nd2,pcd_i_ds_list,im1p_list=generate_stuff(nd2_f,seg_cc_f_nd2, add_edge, ds_sz, outputshape, ds_sz_aff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c9c9b",
   "metadata": {},
   "source": [
    "# 4. registration \n",
    "### step 1. point cloud matching using shape and context information\n",
    "the following code runs ICP and get NCC for each pairs. By default we only consider cases where more than 6 cells appear in the same patch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_mtx_list = run_shape_icp(pcd_j_ds_list,num_cells_list_zstack,\n",
    "                                   pcd_i_ds_list,num_cells_list_nd2, thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92074dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "icp_NCC = run_tranform_get_NCC(transform_mtx_list,ds_sz_aff, \n",
    "                               im2p_list,im1p_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5300f",
   "metadata": {},
   "source": [
    "### step 2. find the consensus set and save the file \n",
    "we find the co-apperance matrix and create the files to run MRS from MATLAB.   \n",
    "`find_consensus_parameters` will find the best parameters for the co-apperance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cent_zstack = get_cellcent(seg_cc_f_zstack)\n",
    "im_cent_nd2 = get_cellcent(seg_cc_f_nd2)\n",
    "final_d_thre,final_thresh,appearance_matrix = find_consensus_parameters(icp_NCC,im_cent_zstack,im_cent_nd2,\n",
    "                                                                          seg_cc_f_zstack,zstack_bb,zstack_cells,\n",
    "                                                                          seg_cc_f_nd2,nd2_bb,nd2_cells,\n",
    "                                                                          add_edge=add_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7cbd1",
   "metadata": {},
   "source": [
    "and save the mat files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de89b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rot_set_f = f'./MRS/'\n",
    "if not os.path.exists(max_rot_set_f):\n",
    "    os.mkdir(max_rot_set_f)    \n",
    "save_MRS_file(max_rot_set_f, im_cent_zstack,im_cent_nd2,appearance_matrix,final_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15e6c4",
   "metadata": {},
   "source": [
    "now run maximum-rotation-set (MRS) from `run_MRS.m` to find the exact matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! /Applications/MATLAB_R2021a.app/bin/matlab -nojvm -nodesktop -nosplash -r \"run_MRS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea0161",
   "metadata": {},
   "source": [
    "load the MRS results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbf9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhat,X_p,Y_p = get_exact_matching_from_MRS(max_rot_set_f, im_cent_zstack,im_cent_nd2, appearance_matrix,final_thresh)``zma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0f84f",
   "metadata": {},
   "source": [
    "### step 3. neighborhood matching \n",
    "- we use the final consensus set coordinates and get their neighbors.\n",
    "- initialize all the coordinates with the consensus set transformation results.\n",
    "- then we can get the final transformation!\n",
    "- we apply this final transformation to the original img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e05b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1p_cent, set2p_cent =get_neighbor_coord(im_cent_zstack,im_cent_nd2,z_f,X_p,Y_p)\n",
    "tran, im1_wahba = run_doubleICP(z_f, nd2_f, bhat, set1p_cent, set2p_cent)  # this is the consensus matching results. \n",
    "total_R, total_shift, total_scale = get_final_transformation(tran,bhat)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the final results. \n",
    "print('rotation matrix:\\n',total_R)\n",
    "print(f'scale:\\n{total_scale}')\n",
    "print('shift:\\n',total_shift)\n",
    "print(f'euler (radiant):\\n{rotationMatrixToEulerAngles(total_R/total_scale)}')\n",
    "print(f'euler (degree):\\n{angles(rotationMatrixToEulerAngles(total_R/total_scale))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67920e0",
   "metadata": {},
   "source": [
    "im1_happy = apply_total_R(z_f,nd2_f, total_R, total_shift)\n",
    "im1_bi_happy = apply_doubleICP_2_binary(seg_cc_f_zstack,seg_cc_f_nd2,total_R,total_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de7a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362a4262",
   "metadata": {},
   "source": [
    "### step 4. iterative non-rigid transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will print out the total NCC over the iterations`\n",
    "img_de,z_de,ncc_list,vec_field_smooth_list = iterive_non_rigid.learn_and_apply_deformable(im1_happy,nd2_f,vec_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a32067",
   "metadata": {},
   "source": [
    "lets look at the registered results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "scl_1 =0.1\n",
    "scl_2 =0.2\n",
    "plt.figure(figsize = (23,11))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gray2RGB(nd2_f, col='r',scl = scl_1) )\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(gray2RGB(nd2_f, col='r',scl = scl_1) + \n",
    "           gray2RGB(z_de, col = 'g', scl = scl_2))\n",
    "plt.yticks([])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(gray2RGB(z_f, col = 'g', scl = scl_2))\n",
    "plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc65433f",
   "metadata": {},
   "source": [
    "### step 5. count the matching cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cffca902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first we apply the non-rigid transformation to the binary image too.\n",
    "z_bi_de = apply_deformable_2_binary(im1_happy,im1_bi_happy,\n",
    "                                    seg_cc_f_zstack,seg_cc_f_nd2,\n",
    "                                    vec_ds,vec_field_smooth_list)\n",
    "\n",
    "# then count the number of matchings. \n",
    "cc_im1,cc_im2,closest_pair,z_cent_new = count_cell_matching(z_bi_de, seg_cc_f_nd2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e726ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167d16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
